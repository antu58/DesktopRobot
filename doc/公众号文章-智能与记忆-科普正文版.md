# 借一个在研项目，聊聊机器人系统里的“智能”与“记忆”

很多人第一次和机器人对话，会有一种“它好像很聪明”的错觉。  
但多聊几次就会发现，真正拉开差距的，不是它会不会说漂亮话，而是两件事：

第一，它能不能在当下做出合适的反应。  
第二，它能不能在下次见到你时，还是那个“连续的它”。

前者我们叫“智能表现”，后者我们叫“记忆系统”。这两条线合在一起，才是一个机器人从“能回答问题”走向“能长期相处”的关键。

## 一、智能表现：决定它这一刻怎么做

### 1）人格不是一句人设文案，而是一组稳定参数

在我们的设计里，人格不是“高冷”“可爱”这种标签，而是一个 5 维向量：

- `empathy`：对他人情绪的响应强度
- `sensitivity`：被外界情绪触发的容易程度
- `stability`：抗波动和恢复能力
- `expressiveness`：表达外显程度
- `dominance`：主导和掌控倾向

人格初值来自 MBTI 映射，但它不是永远不变。长期使用中，系统会根据长期 PAD 统计做缓慢偏移（drift）：

`ΔT_{t+1} = clip((1-γ)ΔT_t + η*q_t, -d_max, d_max)`

最终生效人格是：

`T_eff = clamp(T_base + ΔT, 0, 1)`

这带来的体验很像人：底色稳定，但会被长期经历慢慢塑形。

### 2）情绪表达的核心是 PAD，不是离散标签

很多系统习惯先判一个“开心/生气/难过”标签。我们反过来，先在连续空间里做情绪建模：

- `P`（Pleasure）：愉悦 vs 负向体验
- `A`（Arousal）：平静 vs 激活
- `D`（Dominance）：掌控 vs 受压

标签（如 joy、anxiety、calm）只是解释层，用来方便人读懂，不是底层决策核心。  
情绪强度用连续值计算：

`intensity = clamp(0.65 * sqrt((p^2 + a^2 + d^2)/3) + 0.35 * certainty, 0, 1)`

解释层标签用最近邻：

`emotion = argmin_k ((p-p_k)^2 + (a-a_k)^2 + (d-d_k)^2)`

这样做的好处是：系统不会“非黑即白”，而是能表达“有点不爽但还可控”“紧张但并不恐慌”这种中间状态。

### 3）同一句话，为什么会得到不同处理？

来看一个更贴近日常的场景：

你晚上和同事闹得很不愉快，对机器人说：  
“帮我写一段强硬一点的消息，我现在就发。”

如果机器人当前是“高稳定 + 低唤醒”，它更可能先帮你把诉求整理成不激化冲突的版本。  
如果机器人当前“高表达 + 高唤醒”，并且检测到负向冲击上升，它会先做降温，再给你两个版本（强硬版/克制版），默认推荐克制版；当情绪达到锁定阈值时，还可能暂缓执行。

这背后不是“随机发挥”，而是：人格决定风格，情绪决定节奏与门控。

### 4）外在情绪感知，不是“听懂字面”这么简单

用户输入先被映射到 PAD，然后系统再按人格调制冲击强度。也就是说，同样一句话，对不同人格会产生不同影响。

核心关系可简化为：

`k(T) = 0.55 * ((0.5 + empathy) * (0.5 + sensitivity) / (0.7 + stability))`

`Δx_user = intensity * impact_scale * impact_gain * k(T) * [p, a, d + 0.2*(dominance-0.5)]`

`x_{t+Δ} = clip(x_t + Δx_user + (1 - e^{-λΔ})(x* - x_t), -1, 1)`

`λ = 0.18 * (0.5 + stability) / (1 + 1.5 * shock_load)`

直觉上，`sensitivity` 越高、`stability` 越低，越容易被“带节奏”；`dominance` 会改变对掌控感（D 轴）的响应。  
所以情绪识别一旦误差过大，后面会被动力学放大，这也是为什么必须有置信度门槛和低能量输入衰减策略。

### 5）任务处理要分层：快的快，慢的慢

机器人处理任务时，我们把链路分成三层：

- 硬件反射层：低延迟、强确定性。比如检测到碰撞风险立即刹停，这层不等大模型。
- 意图层：判断“你到底想做什么”。比如“帮我订个明早闹钟顺便提醒带文件”。
- LLM 技能层：处理开放任务。比如让它帮你写一段道歉消息，顺便给三种语气版本。

分层的价值很现实：体验更稳、工程更好测、系统更容易演进。

## 二、记忆系统：决定它下次还是不是同一个它

### 1）先立原则：不同记忆类型，必须用不同技术

“记忆”不是一个数据库表就能解决的。不同记忆天然需要不同存储与检索策略：

- 结构化稳定事实（身份、关系、配置）：数据库
- 当前会话上下文：运行时内存
- 跨会话语义偏好：Mem0/向量检索
- 任务依赖和因果链：图谱类存储
- 资料目录型记忆（PageIndex）：文档索引

这背后的本质是取舍：召回率和噪声、时延和完备性、长期保留和隐私风险，永远要平衡。

### 2）常量式记忆：稳定事实，不要漂

比如“你妈妈叫什么”“你对外怎么称呼客户”“你的城市和时区”。这类信息变化少、错误成本高，适合结构化存储、强校验、低频更新。

### 3）短期记忆：当前会话的工作台

你刚说“周五 3 点开会，提前 20 分钟提醒我，地点改到 B2”，这就是短期工作记忆。  
它的核心是低延迟和及时淘汰，不是长期沉淀。

### 4）长期关键记忆：跨会话的连续性

比如你上个月说过“我对海鲜过敏”“我不喜欢电话沟通更偏向文字确认”，这些信息在未来仍然影响行为。  
长期关键记忆的重点是写入阈值：不是所有聊天都入库，只有“高价值、可复用”的信息才保留。

### 5）资料目录记忆（PageIndex）：记得“有这本书”，不必背下全书

这类记忆很像人脑。  
你可能记得“我看过一本讲习惯养成的书，里面有个两分钟法则”，但你不记得第几章第几页。  
这时系统不该硬编内容，而是通过目录索引找到原资料，再按需回查。

所以资料目录记忆存的是“索引”，不是“全文”：标题、主题标签、来源、时间、定位指针。  
它的价值在于：先保证可追溯，再保证可扩展。

### 6）逻辑性记忆：把关系记住，而不是只记点

现实任务常常是链式的。  
比如“先做体检，再拿报告，再约医生复诊，再调整作息计划”。  
如果只记四个事件点，不记依赖关系，机器人看起来就会“知道很多，但不会安排”。

图谱类记忆的意义就在这里：把时间关系、因果关系、依赖关系显式化。

### 7）记忆有生命周期，不是只进不出

一个健康的记忆系统，至少有这条链路：

采集 -> 判断价值 -> 写入 -> 压缩 -> 检索 -> 更新/遗忘。

真正难的不是“怎么记住”，而是“记什么值得记、什么时候该忘”。

## 结尾：从一次回答，到一段关系

如果只看单轮问答，机器人拼的是模型能力。  
但一旦进入长期使用，真正的竞争力会变成一句话：

智能表现决定“这一刻怎么做”，记忆系统决定“下一次你还是不是那个懂我的你”。

从这个角度看，机器人系统的设计目标，不该是“每次都说得漂亮”，而是“长期稳定地做对的事”。
