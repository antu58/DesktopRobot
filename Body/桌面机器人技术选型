主控芯片：ESP32-S3，可按需求选 1 片或 2 片

单芯片方案：
  型号：ESP32-S3-WROOM-1-N8R8 或 N16R8
  Flash：8MB 起（ESP-SR 模型约 6MB），推荐 8MB 或 16MB
  PSRAM：8MB 起，推荐 8MB 或 16MB

双芯片方案（视觉 / 声音分离）：
  视觉芯片：N8R8（8MB Flash + 8MB PSRAM）— 摄像头、ESP-WHO、舵机
  声音芯片：N8R2 或 N8R8（8MB Flash + 2/8MB PSRAM）— 麦克风阵列、ESP-SR、VAD

视觉：
特定人物识别：ESP-WHO 人脸录入 + 识别（约 500 人）
行人检测：ESP-WHO
手势识别：ESP-DL + 自训练 CNN（可选）
姿态关键点：TFLite MoveNet.Lightning（可选）
复杂行为分析：本地做轻量分类，或关键帧/关键点上传云端
物品识别（待定）

声音：
2～4 麦克风阵列：声源定位（时延/相位差），配合云台转向说话方向
本地 VAD（ESP-SR VADNet）：检测是否有人说话
触发流程：相机检测到人/特定人物 → 开启麦克风监听 → VAD 检测到语音 → 截取语音段 → 上传云端 ASR

舵机（Pan-Tilt 双轴）：
视觉驱动：人物检测框位置 → 计算云台角度 → 对准人
声学驱动：麦克风阵列定位声源方向 → 云台转向 → 再以视觉精对

通信：MQTT，与 Soul 服务端通信

技能：本地存储技能列表，连接服务端时上报，供 LLM 调度执行
  格式：{技能名称, 可选参数}，如 {名称：摇头, 持续时间（可选）：2秒}