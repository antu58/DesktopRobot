# 桌面 AI 机器人架构方案（主控在电脑 + 小体积终端）

> 使用一台高算力本地电脑作为主控大脑，一个或多个小体积终端作为感知与执行单元，构建类似 StackChan 体量、但架构更专业的桌面 AI 机器人。

---

## 1. 设计目标

- 视觉感知（摄像头、人脸 / 目标识别、跟随）
- 语音输入（麦克风）
- 语音输出（扬声器）
- 云台（舵机：俯仰 / 水平旋转）
- 屏幕 / LED（表情、状态）
- 物理交互按钮
- 终端不运行大模型，智能集中在主控或云端

---

## 2. 核心思想

机器人是一个分布式系统：
- 主控：理解、决策、规划
- 终端：采集、执行、反馈

---

## 3. 总体架构

```text
主控（电脑）
 - ASR / Vision / LLM
 - 行为规划
 - 终端通信
        │
   TCP / USB / Wi-Fi
        │
小体积终端（MCU / SBC）
 - 舵机控制
 - 摄像头 / 麦克风
 - 扬声器
 - 屏幕 / LED
 - 按钮
```

---

## 4. 行为流程示例

用户说：“抬头看看我”

1. 音频采集 → 主控
2. ASR → 文本
3. LLM → 意图
4. 行为层生成指令
5. 终端执行舵机动作
6. 状态反馈

```json
{
  "cmd": "MOVE_HEAD",
  "pitch": 30,
  "yaw": 0
}
```

---

## 5. 软件分层

- LLM 层：只输出结构化意图
- 行为控制层（Go）：意图 → 动作 → 指令
- 设备控制层：
  - MCU：C / C++
  - Linux SBC：Python / C++

---

## 6. 屏幕与扬声器设计

- 屏幕 / 扬声器：Linux SBC
- 舵机 / LED / 按钮：MCU
- 不建议 MCU 处理音视频

---

## 7. 终端硬件选型

### MCU
- ESP32
- STM32F4 / F7
- Teensy 4.1

### Linux SBC
- Raspberry Pi Zero 2 W
- Orange Pi Zero 2
- CM4

---

## 8. 通信方式

- USB / 串口（单终端）
- TCP / WebSocket（多终端）
- MQTT（广播）
- UDP（实时视觉）

---

## 9. 终端算力需求

- 不运行大模型
- 512MB ~ 1GB RAM 足够
- 低功耗、小体积

---

## 10. 下一步

- 定义统一指令协议
- 实现最小 Demo（抬头 / 转头 / 表情 / 说话）
- 再引入视觉跟随

---

版本：v4
